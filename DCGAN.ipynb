{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f4c28e-5dd4-415f-878a-78aa9e2b13b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "Seed = 999\n",
    "torch.manual_seed(Seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecf501-f21a-4948-acdf-38ed37595b6e",
   "metadata": {},
   "source": [
    "## Paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51fb87db-2ec6-41e5-8b4c-30197732473c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chemin vers les images\n",
    "dataroot = \"img_align_celeba/\"\n",
    "\n",
    "# Batch size (combien d'image par combien)\n",
    "batch_size = 128\n",
    "\n",
    "# Taille voulue de l'image\n",
    "image_size = 64\n",
    "\n",
    "# Nombre de canaux (1 si greyscale 3 si rgb)\n",
    "nc = 3\n",
    "\n",
    "# Taille du vecteur bruit en entrée du générateur\n",
    "nz = 100\n",
    "\n",
    "# Taille de la feature map du générateur\n",
    "ngf = 64\n",
    "\n",
    "# Taille de la feature map du discriminateur\n",
    "ndf = 64\n",
    "\n",
    "# Nombre d'epochs\n",
    "num_epochs = 10\n",
    "\n",
    "# Learning rate (pas pour la descente de gradient)\n",
    "lr = 0.0001\n",
    "\n",
    "# Hyperparametres pour Adam\n",
    "beta1 = 0.5\n",
    "beta2 = 0.999\n",
    "# Nombre de GPU disponible\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4f4be9-cc19-474c-b03d-da4ad568ac9a",
   "metadata": {},
   "source": [
    "## Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee03aab-8acd-42d8-b690-7aa12a8553de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du dataset\n",
    "dataset = dset.ImageFolder(root=dataroot,\n",
    "                           transform=transforms.Compose([\n",
    "                               transforms.Resize(image_size),\n",
    "                               transforms.CenterCrop(image_size),\n",
    "                               transforms.ToTensor(),\n",
    "                               transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                           ]))\n",
    "\n",
    "# Dataloader pour utiliser le dataset\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
    "                                         shuffle=True, num_workers=2)\n",
    "\n",
    "# Choix du hardware pour les calcul (Si possible GPU)\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "#Vérification\n",
    "real_batch = next(iter(dataloader))\n",
    "px.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff5eff-2b6e-419c-8c74-3f3d6be4fab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisation des poids\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317cad66-042a-417e-ab8d-062a90a55935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generateur DCGAN\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(True),\n",
    "            # Taille. (ngf*8) x 4 x 4\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # Taille. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # Taille. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "            # Taille. (nc) x 64 x 64n_epochs\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e10c4642-05d3-4169-bd22-39b144eb5f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # Taille (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Taille. (ndf) x 32 x 32\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Taille. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Taille. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # Taille. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0769cc1a-c24c-4729-8dda-5672a84ee46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de l'instance du générateur\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Initialisation des poids\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netG)\n",
    "\n",
    "\n",
    "# Création de l'instance du générateur\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "\n",
    "# Initialisation des poids\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Print the model\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379f7e80-038b-436b-8606-8aac5110df52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction de perte (ici Binary Cross Entropy car deux classe réel et fake)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Matrice de bruit fixée\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
    "print(f'Fixed_noise {fixed_noise.shape}')\n",
    "\n",
    "# Attribution des classe pour fake et réel\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# Initialisation des optimiseur\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, beta2))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, beta2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905a93d-01bf-48d4-866b-9e9be8e47e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour garder les informations\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "\n",
    "        ############################\n",
    "        # On entraine D\n",
    "        ###########################\n",
    "        ## Avec les données réelles\n",
    "        netD.zero_grad()\n",
    "        # On adapte le batch\n",
    "        real_cpu = data[0].to(device)#->On met les données sur le bon hardware\n",
    "        b_size = real_cpu.size(0)#->On récupére la taille du batch\n",
    "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
    "        # On récupére la sortie du discriminateur\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # On calcule l'erreur de classification du discriminateur sur les données réelles\n",
    "        errD_real = criterion(output, label)\n",
    "        # On calcule la descente de gradient associé\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## Entrainement sur données simulée\n",
    "        # On génére un batch de données simulées\n",
    "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
    "        # On génére de fausse image depuis le générateur\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # On classifie le batch avec le discriminateur\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # On calcule la perte du discriminateur\n",
    "        errD_fake = criterion(output, label)\n",
    "        # On calcule la descente de gradient associé\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # On calcule la perte de D\n",
    "        errD = (errD_real + errD_fake)/2\n",
    "        # On opère la descente de gradient\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # On entraîne G\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # La perte de G est la perte de D si les images fake étaient vrai\n",
    "        output = netD(fake).view(-1)\n",
    "        # On calcule perte de G\n",
    "        errG = criterion(output, label)\n",
    "        # On calcule la descente de gradient associé\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # On opère la descente de gradient associé\n",
    "        optimizerG.step()\n",
    "\n",
    "        # On print quelques infos\n",
    "        if i % 500 == 0:\n",
    "            print(f'[{epoch}/{num_epochs}][{i}/{len(dataloader)}]\\tLoss_D: {errD.item()}\\tLoss_G: {errG.item()}\\tD(x): {D_x}\\tD(G(z)): {D_G_z1} / {D_G_z2}')\n",
    "\n",
    "        # On enregistre les loss\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "    #On enregiste un lot d'image par epoch\n",
    "    with torch.no_grad():\n",
    "        fake = netG(fixed_noise).detach().cpu()\n",
    "        img_list.append(vutils.make_grid(fake, padding=2, normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd8e588-282c-48e4-af2d-028482f4da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pour sauvegarder les images\n",
    "for img, i in zip(img_list,range(10)):\n",
    "    fig=px.imshow(np.transpose(img,(1,2,0)))\n",
    "    fig.write_image(f\"DCGAN/{i}.jpeg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
